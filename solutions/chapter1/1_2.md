### Q: Many tic-tac-toe positions appear different but are really the same because of symmetries. How might we amend the learning process described above to take advantage of this? In what ways would this change improve the learning process? Now think again. Suppose the opponent did not take advantage of symmetries. In that case, should we? Is it true, then, that symmetrically equivalent positions should necessarily have the same value?

A: Assuming position means state in this context,

The learning process can be ammended to update all symmetric positions together at the update step.

This would reduce the time for the policy to converge.

If the opponent did not take advantage of the symmetries, it wouldn't matter much. It still would be faster for us to use those symmetries.
