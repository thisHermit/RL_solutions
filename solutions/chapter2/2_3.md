### Q: In the comparison shown in Figure 2.2, which method will perform best in the long run in terms of cumulative reward and probability of selecting the best action? How much better will it be? Express your answer quantitatively.

A: Ignoring e = 0 as it will not perform optimally,

In the long term, the optimal Q value would be learnt by the e = 0.1 and e = 0.01

Using subscript 1 for e=0.1 and subscript 2 for e=0.01
and let P be the probability of selecting the best action and G be the cumulative reward. Then, P1

= (1-e) + e/10

= 0.9 + 0.01

P1 = 0.91

and similarly P2 = 0.991

G1 = 0.91x(optimal reward) + 0.09x(other reward)

similarly G2 = 0.991x(optimal reward) + 0.009x(other reward)

Their difference comes out to

P = 0.081
G = 0.081x(optimal reward) -0.081x(other reward)
